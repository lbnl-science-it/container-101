<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="June 10, 2020" />
  <title>Container 101 on Lawrencium</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Container 101 on Lawrencium</h1>
  <p class="author">
June 10, 2020
  </p>
  <p class="date">Wei Feinstein</p>
</div>
<div id="outline" class="slide section level1">
<h1>Outline</h1>
<ul>
<li>Lawrencium Supercluster overview</li>
<li>Computing resources &amp; services<br />
</li>
<li>Container technology overview</li>
<li>Build singularity containers</li>
<li>Run singularity containers on Lawrencium</li>
</ul>
</div>
<div id="lawrencium-cluster-overview" class="slide section level1">
<h1>Lawrencium Cluster Overview</h1>
<center>
<img src="figures/lrc.png" width="80%">
</center>
</div>
<div id="accounts-on-lawrencium" class="slide section level1">
<h1>Accounts on Lawrencium</h1>
<h3 id="three-types-of-project-accounts">Three types of Project Accounts</h3>
<ul>
<li>PI Computing Allowance (PCA) account: free 300K SUs per year (pc_xxx)</li>
<li>Condo account: PIs buy in compute nodes to the general condo pool (lr_xxx)</li>
<li>Recharge account: with minimal recharge rate ~ $0.01/SU (ac_xxx)</li>
</ul>
<p><a href="%5Bhttps://sites.google.com/a/lbl.gov/hpc/getting-an-account">https://sites.google.com/a/lbl.gov/hpc/getting-an-account</a></p>
<h3 id="user-accounts">User accounts</h3>
<ul>
<li>User account request</li>
<li>User agreement consent</li>
</ul>
<p><a href="https://sites.google.com/a/lbl.gov/hpc/getting-an-account">https://sites.google.com/a/lbl.gov/hpc/getting-an-account</a></p>
</div>
<div id="softwre-module-farm" class="slide section level1">
<h1>Softwre Module Farm</h1>
<h3 id="module-commands">Module commands</h3>
<ul>
<li><em>module purge</em>: clear user’s work environment</li>
<li><em>module avail</em>: check available software packages</li>
<li><em>module load xxx</em>: load a package</li>
<li><em>module list</em>: check currently loaded software</li>
<li>Users may install their own software</li>
</ul>
<p><a href="https://sites.google.com/a/lbl.gov/high-performance-computing-services-group/getting-started/sl6-module-farm-guide">https://sites.google.com/a/lbl.gov/high-performance-computing-services-group/getting-started/sl6-module-farm-guide</a></p>
</div>
<div id="slurm-resource-manager-job-scheduler" class="slide section level1">
<h1>SLURM: Resource Manager &amp; Job Scheduler</h1>
<h3 id="jub-submission">Jub Submission</h3>
<ul>
<li>sbatch: submit a job to the batch queue system</li>
</ul>
<pre><code>sbatch myjob.sh</code></pre>
<ul>
<li>srun: request an interactive node(s) and login automatically</li>
</ul>
<pre><code>srun -A ac_xxx -p lr5 -q lr_normal -t 1:0:0 --pty bash</code></pre>
<ul>
<li>salloc : request an interactive node(s)</li>
</ul>
<pre><code>salloc –A pc_xxx –p lr6 –q lr_debug –t 0:30:0</code></pre>
</div>
<div id="job-monitoring" class="slide section level1">
<h1>Job Monitoring</h1>
<ul>
<li>sinfo: check status of partitions and nodes (idle, allocated, drain, down)</li>
</ul>
<pre><code>sinfo –r –p lr6</code></pre>
<ul>
<li>squeue: check jobs in the batch queuing system (R or PD)</li>
</ul>
<pre><code>squeue –u $USER</code></pre>
<ul>
<li>sacct: check job information or history</li>
</ul>
<pre><code>sacct -X -o ‘jobid,user,partition,nodelist,stat’</code></pre>
<ul>
<li>scancel : cancel a job</li>
</ul>
<pre><code>scancel jobID</code></pre>
<p><a href="https://sites.google.com/a/lbl.gov/high-performance-computing-services-group/scheduler/slurm-usage-instructions">https://sites.google.com/a/lbl.gov/high-performance-computing-services-group/scheduler/slurm-usage-instructions</a></p>
</div>
<div id="services-1" class="slide section level1">
<h1>Services (1)</h1>
<ul>
<li>Designate data transfer node <strong>lrc-xfer.lbl.gov</strong>
<ul>
<li>scp -r /your/source/file $USER@lrc-xder.lbl.gov:/cluster/path</li>
<li>rsync -avzh /your/source/file $USER <span class="citation">@lrc-xfer.lbl.gov:/cluster/path</span></li>
</ul></li>
<li>Globus Online provide secured unified interface for data transfer
<ul>
<li>endpoint lbn#lrc, Globus Connect, AWS S3 connect</li>
</ul></li>
<li>Visualization and remote desktop
<ul>
<li>Detailed information <a href="https://sites.google.com/a/lbl.gov/high-performance-computing-services-group/getting-started/remote-desktop">click here</a></li>
</ul></li>
</ul>
</div>
<div id="service-2-jupyterhub" class="slide section level1">
<h1>Service (2): Jupyterhub</h1>
<a href="https://lrc-jupyter.lbl.gov">LRC Jupyterhub</a>
<center>
<img src="figures/jupyter.png" width="70%">
</center>
</div>
<div id="services-3-cloud-computing" class="slide section level1">
<h1>Services (3): Cloud Computing</h1>
<ul>
<li>LBNL has a master payer program for cloud services on Amazon Web Services (AWS) and Google Cloud Platform (GCP).<br />
</li>
<li>No charge to have an account in the program</li>
<li>Charges only for actual usage of cloud services like storage or compute</li>
<li>Monthly billing for cloud usage are direct to your PID via recharge mechanism</li>
<li>Simple enrollment process.</li>
<li>De-enrollment only changes the billing setup in your account, and your account will continue to be active.</li>
<li>Complete control of your own AWS or GCP dashboard, your data, tools, and services.</li>
</ul>
</div>
<div id="aws-gcp-services" class="slide section level1">
<h1>AWS &amp; GCP Services</h1>
<ul>
<li>AWS and GCP make discounts available to LBNL users.</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Type</th>
<th>AWS</th>
<th>GCP</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Overall</td>
<td>7%</td>
<td>13%</td>
<td></td>
</tr>
<tr class="even">
<td>Data Egress</td>
<td>15%</td>
<td>25%</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>AWS, <a href="https://aws.amazon.com/blogs/publicsector/aws-offers-data-egress-discount-to-researchers/">restrictions apply</a></li>
<li>Over 125 people at LBNL with cloud accounts on AWS and GCP.<br />
</li>
<li>Mostly use virtual machines and storage, containers, ML, AI, and data visualization</li>
<li>To set up a cloud account on either AWS or GCP, send email to <a href="mailto:scienceit@lbl.gov">scienceit@lbl.gov</a></li>
</ul>
</div>
<div id="virtual-machine-services" class="slide section level1">
<h1>Virtual Machine Services</h1>
<p><left><img src="figures/vm.png" width="60%"></left></p>
<p>More information of VM click <a href="https://commons.lbl.gov/display/itfaq/SVM+-+Virtual+Machine+Hosting">here</a></p>
</div>
<div id="containerization" class="slide section level1">
<h1>Containerization</h1>
<ul>
<li>Technology of putting an application and all of its dependencies into a single package.</li>
<li>Portable, shareable, and reproducible.</li>
<li>Your application brings its environment with it.</li>
</ul>
<h4 id="examples">Examples</h4>
<ul>
<li>Package an analysis pipeline so that it runs on your laptop, in the cloud, and in HPC environment to produce the same result.</li>
<li>Publish a paper and include a link to a container with all of the data and software that you used so that others can easily reproduce your results.</li>
<li>Install and run an application that requires a complicated stack of dependencies</li>
</ul>
</div>
<div id="container-vs.-virtual-machine" class="slide section level1">
<h1>Container vs. Virtual Machine</h1>
<p><left><img src="figures/vm-sif.png" width="70%"></left></p>
</div>
<div id="singularity-technology" class="slide section level1">
<h1>Singularity Technology</h1>
<ul>
<li>Open-source computer software that encapsulates an application and all its dependencies into a single image</li>
<li>Bring containers and reproducibility to scientific computing and HPC</li>
<li>Developed by Greg Kurtzer</li>
<li>Typically users have a build system as root users, but may not be root users on a production system</li>
</ul>
</div>
<div id="singularity-workflow" class="slide section level1">
<h1>Singularity Workflow</h1>
<ul>
<li>Install Singularity on a local machine</li>
<li>Build Singularity containers locally with a root permission</li>
<li>Transfer containers to LRC clusters</li>
<li>Run containers on the cluster
<ul>
<li>Root privilege is not permitted</li>
</ul></li>
</ul>
</div>
<div id="singularity-installation" class="slide section level1">
<h1>Singularity Installation</h1>
<p>OS platforms</p>
<pre><code>- Linux
- Mac
- Window</code></pre>
<p>Refer to instructions <a href="https://github.com/lbnl-science-it/container-101/blob/master/singularity_installation_guide.md">here</a> for details</p>
<p>Test your installation:</p>
<pre><code>$ singularity --version 
$ singularity run docker://godlovedc/lolcow</code></pre>
</div>
<div id="create-singularity-containers" class="slide section level1">
<h1>Create Singularity Containers</h1>
<ul>
<li>Build from docker containers
<ul>
<li><a href="https://hub.docker.com/search?q=&amp;type=image">Docker hub</a></li>
<li><a href="https://cloud.sylabs.io/library">Sylabs Cloud</a> and <a href="https://singularity-hub.org/">Singularity hub</a></li>
<li><a href="https://www.nvidia.com/en-us/gpu-cloud/containers/">Nvidia HPC containers</a></li>
<li><a href="https://biocontainers.pro/#/registry">Biocontainers</a></li>
<li><a href="https://aws.amazon.com/releasenotes/available-deep-learning-containers-images/">AWS</a></li>
</ul></li>
<li>Build using definition files or recipes</li>
</ul>
</div>
<div id="singularity-pull-directly-from-dockerhub-singularity-hub" class="slide section level1">
<h1>Singularity pull directly from Dockerhub &amp; Singularity hub</h1>
<ul>
<li>No root/sudo privilege is needed</li>
<li>Create immutable squashfs containers</li>
</ul>
<pre><code>singularity pull --help</code></pre>
<ul>
<li>Docker Hub:  Pull a container from Docker Hub.</li>
</ul>
<pre><code>singularity pull docker://ubuntu:18.04 
singularity pull docker://gcc:7.2.0</code></pre>
<ul>
<li>Singularity Hub:  If no tag is specified, the master branch of the repository is used</li>
</ul>
<pre><code>singularity pull hello-world.sif shub://singularityhub/hello-world</code></pre>
</div>
<div id="singularity-pull-when-docker-containers-provided-by-other-docker-repos" class="slide section level1">
<h1>Singularity pull when Docker Containers Provided by Other docker repos</h1>
<p><a href="https://www.nvidia.com/en-us/gpu-cloud/containers/">Nvidia HPC containers</a> <a href="https://biocontainers.pro/#/registry">Biocontainers</a> <a href="https://aws.amazon.com/releasenotes/available-deep-learning-containers-images/">AWS</a></p>
<p>Steps to build singularity containers:</p>
<ul>
<li>Build a docker container locally</li>
</ul>
<pre><code>docker pull nvcr.io/hpc/pgi-compilers:ce
.....
docker images
nvcr.io/hpc/pgi-compilers                  ce                         c13ce6cf7f66        6 months ago        9.9GB
openmpi3.1                                 latest                     08a5518bb344        9 months ago        14.3GB
registry                                   2                          f32a97de94e1        15 months ago       25.8MB
...</code></pre>
<ul>
<li>Push to the Docker Hub (docker login) or simply use your local docker registry</li>
<li>Singularity build from local registry</li>
</ul>
<pre><code>singularity build pgi.sif docker-daemon://nvcr.io/hpc/pgi-compilers:ce
</code></pre>
<p>Another example of using docker containers from <a href="https://github.com/lbnl-science-it/singularity_aws_dl_container">AWS</a></p>
</div>
<div id="run-singularity-with-shell-run-exec" class="slide section level1">
<h1>Run Singularity with shell, run, exec</h1>
<ul>
<li><strong>shell</strong> sub-command: invokes an interactive shell within a container</li>
</ul>
<pre><code>singularity shell hello-world.sif</code></pre>
<ul>
<li><strong>run</strong> sub-command: executes the container’s runscript</li>
</ul>
<pre><code>singularity run hello-world.sif </code></pre>
<ul>
<li><strong>exec</strong> sub-command: execute an arbitrary command within container</li>
</ul>
<pre><code>singularity exec hello-world.sif cat /etc/os-release</code></pre>
</div>
<div id="singularity-build" class="slide section level1">
<h1>Singularity build</h1>
<ul>
<li>Root/sudo privilege is needed</li>
</ul>
<pre><code>singularity build --help</code></pre>
<ul>
<li>Build from a definition file</li>
</ul>
<pre><code>sudo singularity --debug build mycontainer.sif Singularity </code></pre>
</div>
<div id="defination-filerecipe" class="slide section level1">
<h1>Defination File/Recipe</h1>
<pre><code>Bootstrap: docker
#library, docker, shub, localimage, yum, debootstrap, arch, busybox, zypper 
From: ubuntu

# used singularity run-help 
%help
Hello. I&#39;m in the container.

# executed on host after the base OS is installed.
%setup
    touch ${SINGULARITY_ROOTFS}/tacos.txt
    echo “I love avocado” &gt;&gt; avocados.txt

# copy files from your host system into the container 
%files
    avocados.txt /opt    

%environment
  export NAME=avocado

# executed within the container after the base OS is installed at build time
#install new software and libraries, config files,  directories, etc
%post
    echo &#39;export Avocado=TRUE &gt;&gt; $SINGULARITY_ENVIRONMENT

# executed when the container image is run:  singularity run
%runscript 
    echo &quot;Hello! Arguments received: $* \n&quot;
    exec echo &quot;$@&quot;  </code></pre>
</div>
<div id="singularity-build-rewritable-sandbox" class="slide section level1">
<h1>Singularity Build Rewritable Sandbox</h1>
<ul>
<li>Can be built from a recipe or existing container</li>
<li>Used to develop, test, and make changes, then build or convert it into a standard image</li>
</ul>
<pre><code>sudo singularity build --sandbox build gccbox docker://gcc:7.2.0
sudo singularity build --sandbox build test-box Singularity </code></pre>
<ul>
<li>When you want to alter your image, you can use commands like shell, exec, run, with the –writable option</li>
</ul>
<pre><code>sudo singularity shell --writable test-box</code></pre>
<ul>
<li>Convert a sandbox to an immutable final container:</li>
</ul>
<pre><code>sudo singularity build test-box.sif test-box</code></pre>
</div>
<div id="inspect-containers" class="slide section level1">
<h1>Inspect containers</h1>
<ul>
<li>To check how a image is built, running script and environment variables..</li>
</ul>
<pre><code>singularity inspect [options] image_name
    --lablels
    --runscript
    --deffile
    --environment
e.g. singularity inspect --deffile mycontainer.sif</code></pre>
</div>
<div id="singularity-python-spython" class="slide section level1">
<h1>Singularity Python (spython)</h1>
<ul>
<li>Python API for Singularity containers</li>
<li>Convert Dockerfile to Singularity def</li>
</ul>
<pre><code>spython recipe Dockerfile &gt; dock2sif.def</code></pre>
</div>
<div id="run-singularity-containers-on-lawrencium" class="slide section level1">
<h1>Run Singularity Containers on Lawrencium</h1>
<ul>
<li>File transfer to LRC cluster</li>
</ul>
<pre><code>scp xxx.sif $USER@lrc-xfer.lbl.gov:/your/path/on/cluster </code></pre>
<ul>
<li>Run your container interactively
<ul>
<li>Request an interactive compute node</li>
</ul>
<pre><code>singularity shell/run/exec container.sif</code></pre></li>
<li>Submit a slurm job</li>
</ul>
</div>
<div id="job-submission-example" class="slide section level1">
<h1>Job Submission Example</h1>
<pre><code>#!/bin/bash -l
#SBATCH --job-name=container-test        
#SBATCH --partition=lr5          
#SBATCH --account=ac_xxx         
#SBATCH --qos=lr_normal         
#SBATCH --nodes=1           
#SBATCH --time=1-2:0:0          

cd $SLURM_SUBMIT_DIR
singularity exec mycontainer.sif cat /etc/os-release</code></pre>
</div>
<div id="container-bind-path" class="slide section level1">
<h1>Container bind path</h1>
<ul>
<li>Singularity allow mapping directories on host to directories within container</li>
<li>Easy data access within containers</li>
<li>System-defined bind paths on LRC
<ul>
<li>/global/home/users/</li>
<li>/global/scratch/</li>
</ul></li>
<li>User can define own bind paths:</li>
<li>e.g.: mount /host/path/ on the host to /container/path inside the container</li>
</ul>
<pre><code>-B /host/path/:/container/path
singularity shell --nv -B /clusterfs/bear:/tmp pytorch_19_12_py3.sif</code></pre>
</div>
<div id="run-gpu-containers-and-mpi-containers" class="slide section level1">
<h1>Run GPU Containers and MPI Containers</h1>
<ul>
<li>Singularity supports NVIDIA’s CUDA GPU compute framework or AMD’s ROCm solution</li>
<li>–nv enables NVIDIA GPU support in Singularity</li>
<li>Remember to request a GPU node from the ES1 partition</li>
</ul>
<pre><code>singularity exec --nv pytorch_19_12_py3.sif python -c &quot;import torch; print(torch.__version__)&quot;
1.4.0a0+a5b4d78</code></pre>
<h2 id="run-mpi-containers">Run MPI Containers</h2>
<ul>
<li>If launch on multiple nodes, MPI libraries on the host and inside the container need to match</li>
<li>If launch on one node, MPI library inside the container is called</li>
</ul>
</div>
<div id="getting-help" class="slide section level1">
<h1>Getting help</h1>
<ul>
<li>Virtual Office Hours:
<ul>
<li>Time: 10:30am - noon (Wednesdays)</li>
<li>Request <a href="https://docs.google.com/forms/d/e/1FAIpQLScBbNcr0CbhWs8oyrQ0pKLmLObQMFmYseHtrvyLfOAoIInyVA/viewform">online</a></li>
</ul></li>
<li>Sending us tickets at hpcshelp@lbl.gov</li>
<li>More information, documents, tips of how to use LBNL Supercluster <a href="http://scs.lbl.gov">http://scs.lbl.gov/</a></li>
<li>DLab consulting: https://dlab.berkeley.edu/consulting</li>
</ul>
<p>Please fill out <a href="https://docs.google.com/forms/d/e/1FAIpQLSdrmW-7gZ8FankQwEceY6r_uXPmLHAuXFjDDfwu-86A1a0llg/viewform">Training Survey</a> to get your comments and help us improve.</p>
</div>
</body>
</html>
